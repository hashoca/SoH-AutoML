{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "741d0681-74c2-4bc6-83bc-a8336a92a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob, zipfile, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Yol ayarları (CSV’ler notebook ile aynı klasördeyse \".\")\n",
    "DATA_DIR = \".\"\n",
    "OUT_DIR  = \"./outputs_flaml_shap\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# FLAML ayarları\n",
    "TIME_BUDGET_SEC = 180   # her LOCO eğitimi için süre bütçesi (artırılabilir: 300-900)\n",
    "SEED = 42\n",
    "N_JOBS = -1\n",
    "\n",
    "# Çizimler\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43aebbed-fb9a-4d8f-a5fd-26b7863ff726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    \"\"\"Küçük harfe çevir + harf/rakam dışını sil (space/_/-)\"\"\"\n",
    "    return re.sub(r\"[^a-z0-9]\", \"\", str(s).strip().lower())\n",
    "\n",
    "TARGET_ALIASES = {\n",
    "    \"soh\": {\"soh\",\"stateofhealth\",\"y\",\"health\"}\n",
    "}\n",
    "FEATURE_ALIASES = {\n",
    "    \"cycle\": {\"cycle\",\"cycles\",\"efc\",\"equivalentfullcycles\",\"ncycle\",\"cyclecount\"},\n",
    "    \"peak\":  {\"peak\",\"pmax\",\"icpeak\",\"normalizedpeak\",\"normalizedpmax\",\"normalizedicpeak\",\"pmaxnorm\",\"pmaxnormalized\",\"p_max\"},\n",
    "    \"meanT\": {\"meant\",\"temperature\",\"temp\",\"meantemp\",\"avgtemp\",\"meantemperature\",\"averagetemperature\",\"tmean\",\n",
    "              \"mean_temperature\",\"mean-temperature\",\"mean temperature\"}\n",
    "}\n",
    "TARGET_ALIASES = {k: {_norm(x) for x in v} for k,v in TARGET_ALIASES.items()}\n",
    "FEATURE_ALIASES = {k: {_norm(x) for x in v} for k,v in FEATURE_ALIASES.items()}\n",
    "\n",
    "def _find_index(colnames, alias_set):\n",
    "    norm_cols = [_norm(c) for c in colnames]\n",
    "    for i, n in enumerate(norm_cols):\n",
    "        if n in alias_set:\n",
    "            return i\n",
    "    # kısmi eşleşme fallback (örn meantemperature içinde temperature)\n",
    "    for i, n in enumerate(norm_cols):\n",
    "        for a in alias_set:\n",
    "            if a and a in n:\n",
    "                return i\n",
    "    return None\n",
    "\n",
    "def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols = list(df.columns)\n",
    "\n",
    "    soh_idx   = _find_index(cols, TARGET_ALIASES[\"soh\"])\n",
    "    cycle_idx = _find_index(cols, FEATURE_ALIASES[\"cycle\"])\n",
    "    peak_idx  = _find_index(cols, FEATURE_ALIASES[\"peak\"])\n",
    "    temp_idx  = _find_index(cols, FEATURE_ALIASES[\"meanT\"])\n",
    "\n",
    "    missing = []\n",
    "    if soh_idx   is None: raise ValueError(f\"Hedef (SoH) kolonu bulunamadı. Mevcut: {cols}\")\n",
    "    if cycle_idx is None: missing.append(\"cycle\")\n",
    "    if peak_idx  is None: missing.append(\"peak\")\n",
    "    if temp_idx  is None: missing.append(\"meanT\")\n",
    "    if missing:\n",
    "        raise ValueError(f\"Zorunlu feature kolon(lar) bulunamadı: {missing}\\nMevcut kolonlar: {cols}\")\n",
    "\n",
    "    df_std = pd.DataFrame({\n",
    "        \"cycle\": pd.to_numeric(df.iloc[:, cycle_idx], errors=\"coerce\"),\n",
    "        \"peak\":  pd.to_numeric(df.iloc[:,  peak_idx], errors=\"coerce\"),\n",
    "        \"meanT\": pd.to_numeric(df.iloc[:,  temp_idx], errors=\"coerce\"),\n",
    "        \"soh\":   pd.to_numeric(df.iloc[:,   soh_idx], errors=\"coerce\"),\n",
    "    }).dropna()\n",
    "\n",
    "    return df_std\n",
    "\n",
    "def infer_cell_id_from_path(path: str) -> str:\n",
    "    base = os.path.basename(path)\n",
    "    m = re.search(r\"(Cell\\s*\\d+)\", base, flags=re.I)\n",
    "    return m.group(1).replace(\" \", \"\") if m else os.path.splitext(base)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517efece-632b-4ab3-a129-aaace4c161c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cycle</th>\n",
       "      <th>peak</th>\n",
       "      <th>meanT</th>\n",
       "      <th>soh</th>\n",
       "      <th>Cell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.098876</td>\n",
       "      <td>40.049519</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Cell1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4.807921</td>\n",
       "      <td>39.993983</td>\n",
       "      <td>99.220226</td>\n",
       "      <td>Cell1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>4.723264</td>\n",
       "      <td>39.992577</td>\n",
       "      <td>98.608316</td>\n",
       "      <td>Cell1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>4.652136</td>\n",
       "      <td>40.006883</td>\n",
       "      <td>98.031960</td>\n",
       "      <td>Cell1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>4.442668</td>\n",
       "      <td>39.988917</td>\n",
       "      <td>97.487351</td>\n",
       "      <td>Cell1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cycle      peak      meanT         soh   Cell\n",
       "0      0  5.098876  40.049519  100.000000  Cell1\n",
       "1    100  4.807921  39.993983   99.220226  Cell1\n",
       "2    200  4.723264  39.992577   98.608316  Cell1\n",
       "3    300  4.652136  40.006883   98.031960  Cell1\n",
       "4    400  4.442668  39.988917   97.487351  Cell1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yüklendi: 8 dosya, 519 satır, Kolonlar: ['cycle', 'peak', 'meanT', 'soh', 'Cell']\n"
     ]
    }
   ],
   "source": [
    "SEARCH_PAT = \"Cell*_Cycle_Peak_meanT_SoH.csv\"\n",
    "\n",
    "csv_paths = sorted(glob.glob(os.path.join(DATA_DIR, SEARCH_PAT)))\n",
    "if not csv_paths:\n",
    "    raise FileNotFoundError(f\"'{SEARCH_PAT}' bulunamadı. Çalışma dizini: {os.getcwd()}\")\n",
    "\n",
    "dfs = []\n",
    "for p in csv_paths:\n",
    "    raw = pd.read_csv(p)\n",
    "    std = standardize_columns(raw)\n",
    "    std[\"Cell\"] = infer_cell_id_from_path(p)\n",
    "    dfs.append(std)\n",
    "\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "display(data.head())\n",
    "print(f\"Yüklendi: {len(csv_paths)} dosya, {data.shape[0]} satır, Kolonlar: {list(data.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d67c295a-e43d-43fa-8021-9fb659127cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561c981555f44526812ac6479e58d1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LOCO:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Cell</th>\n",
       "      <th>Best_Estimator</th>\n",
       "      <th>Best_Config</th>\n",
       "      <th>Best_Iteration</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cell1</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>{'n_estimators': 440, 'max_leaves': 11, 'min_c...</td>\n",
       "      <td>312</td>\n",
       "      <td>0.522933</td>\n",
       "      <td>0.375982</td>\n",
       "      <td>0.993837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cell2</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'n_estimators': 445, 'num_leaves': 7, 'min_ch...</td>\n",
       "      <td>353</td>\n",
       "      <td>0.779598</td>\n",
       "      <td>0.521048</td>\n",
       "      <td>0.986479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cell3</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'n_estimators': 231, 'num_leaves': 14, 'min_c...</td>\n",
       "      <td>270</td>\n",
       "      <td>0.572419</td>\n",
       "      <td>0.424850</td>\n",
       "      <td>0.992138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cell4</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>{'n_estimators': 280, 'max_leaves': 15, 'min_c...</td>\n",
       "      <td>267</td>\n",
       "      <td>0.626900</td>\n",
       "      <td>0.543891</td>\n",
       "      <td>0.989334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell5</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'n_estimators': 472, 'num_leaves': 10, 'min_c...</td>\n",
       "      <td>389</td>\n",
       "      <td>0.716865</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.982560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cell6</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'n_estimators': 472, 'num_leaves': 9, 'min_ch...</td>\n",
       "      <td>414</td>\n",
       "      <td>0.556837</td>\n",
       "      <td>0.469195</td>\n",
       "      <td>0.989640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cell7</td>\n",
       "      <td>extra_tree</td>\n",
       "      <td>{'n_estimators': 92, 'max_features': 0.9031334...</td>\n",
       "      <td>346</td>\n",
       "      <td>1.546465</td>\n",
       "      <td>1.394771</td>\n",
       "      <td>0.921774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cell8</td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'n_estimators': 442, 'num_leaves': 14, 'min_c...</td>\n",
       "      <td>446</td>\n",
       "      <td>0.752366</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>0.986256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test_Cell Best_Estimator                                        Best_Config  \\\n",
       "0     Cell1        xgboost  {'n_estimators': 440, 'max_leaves': 11, 'min_c...   \n",
       "1     Cell2           lgbm  {'n_estimators': 445, 'num_leaves': 7, 'min_ch...   \n",
       "2     Cell3           lgbm  {'n_estimators': 231, 'num_leaves': 14, 'min_c...   \n",
       "3     Cell4        xgboost  {'n_estimators': 280, 'max_leaves': 15, 'min_c...   \n",
       "4     Cell5           lgbm  {'n_estimators': 472, 'num_leaves': 10, 'min_c...   \n",
       "5     Cell6           lgbm  {'n_estimators': 472, 'num_leaves': 9, 'min_ch...   \n",
       "6     Cell7     extra_tree  {'n_estimators': 92, 'max_features': 0.9031334...   \n",
       "7     Cell8           lgbm  {'n_estimators': 442, 'num_leaves': 14, 'min_c...   \n",
       "\n",
       "   Best_Iteration      RMSE       MAE        R2  \n",
       "0             312  0.522933  0.375982  0.993837  \n",
       "1             353  0.779598  0.521048  0.986479  \n",
       "2             270  0.572419  0.424850  0.992138  \n",
       "3             267  0.626900  0.543891  0.989334  \n",
       "4             389  0.716865  0.292135  0.982560  \n",
       "5             414  0.556837  0.469195  0.989640  \n",
       "6             346  1.546465  1.394771  0.921774  \n",
       "7             446  0.752366  0.691200  0.986256  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KAYIT] Sonuç tablosu: ./outputs_flaml_shap\\flaml_loco_results.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 768x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results = []\n",
    "all_cells = sorted(data[\"Cell\"].unique(), key=lambda x: int(re.sub(r\"\\D\",\"\",x)))  # Cell1..Cell8 sıralı\n",
    "\n",
    "for test_cell in tqdm(all_cells, desc=\"LOCO\"):\n",
    "    train_df = data[data[\"Cell\"] != test_cell].copy()\n",
    "    test_df  = data[data[\"Cell\"] == test_cell].copy()\n",
    "\n",
    "    if len(test_df) == 0 or len(train_df) == 0:\n",
    "        print(f\"[UYARI] {test_cell}: Boş fold, atlandı.\")\n",
    "        continue\n",
    "\n",
    "    X_train = train_df[[\"cycle\",\"peak\",\"meanT\"]].copy()\n",
    "    y_train = train_df[\"soh\"].copy()\n",
    "    X_test  = test_df[[\"cycle\",\"peak\",\"meanT\"]].copy()\n",
    "    y_test  = test_df[\"soh\"].copy()\n",
    "\n",
    "    # Güvenli numeric + NaN temizliği\n",
    "    X_train = X_train.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    X_test  = X_test.apply(pd.to_numeric,  errors=\"coerce\")\n",
    "    y_train = pd.to_numeric(y_train, errors=\"coerce\")\n",
    "    y_test  = pd.to_numeric(y_test,  errors=\"coerce\")\n",
    "\n",
    "    tr_mask = np.isfinite(X_train.values).all(axis=1) & np.isfinite(y_train.values)\n",
    "    te_mask = np.isfinite(X_test.values).all(axis=1)  & np.isfinite(y_test.values)\n",
    "    X_train, y_train = X_train.loc[tr_mask], y_train.loc[tr_mask]\n",
    "    X_test,  y_test  = X_test.loc[te_mask],  y_test.loc[te_mask]\n",
    "\n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        print(f\"[UYARI] {test_cell}: NaN/inf temizliği sonrası boş veri, atlandı.\")\n",
    "        continue\n",
    "\n",
    "    # FLAML\n",
    "    automl = AutoML()\n",
    "    automl.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        task=\"regression\",\n",
    "        time_budget=TIME_BUDGET_SEC,\n",
    "        metric=\"rmse\",\n",
    "        estimator_list=[\"lgbm\",\"xgboost\",\"rf\",\"extra_tree\"],  # ağaç odaklı, SHAP uyumlu\n",
    "        n_jobs=N_JOBS,\n",
    "        seed=SEED,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Tahmin & metrikler (sklearn sürümünden bağımsız RMSE)\n",
    "    y_pred = automl.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = float(np.sqrt(mse))\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Test_Cell\": test_cell,\n",
    "        \"Best_Estimator\": automl.best_estimator,\n",
    "        \"Best_Config\": automl.best_config,\n",
    "        \"Best_Iteration\": automl.best_iteration,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\":  mae,\n",
    "        \"R2\":   r2,\n",
    "    })\n",
    "\n",
    "    # ==== SHAP ====\n",
    "    # Arka plan örneklemi (Explainer maliyetini düşürmek için)\n",
    "    bg = X_train.sample(min(1000, len(X_train)), random_state=SEED)\n",
    "\n",
    "    # FLAML wrapper → gerçek model\n",
    "    base_model = getattr(automl.model, \"model\", automl.model)\n",
    "    shap_arr = None\n",
    "\n",
    "    # 1) Ağaç modelleri için TreeExplainer (en hızlı/kararlı)\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(base_model)\n",
    "        shap_arr = explainer.shap_values(X_test)\n",
    "        if isinstance(shap_arr, list):  # bazen sınıf-listesi dönebilir\n",
    "            shap_arr = shap_arr[0]\n",
    "        shap_arr = np.asarray(shap_arr)\n",
    "    except Exception:\n",
    "        # 2) Genel Explainer (masker ile)\n",
    "        try:\n",
    "            masker = shap.maskers.Independent(bg, max_samples=1000)\n",
    "            explainer = shap.Explainer(base_model, masker)\n",
    "            sv = explainer(X_test, check_additivity=False)\n",
    "            shap_arr = np.asarray(sv.values)\n",
    "        except Exception as e_auto:\n",
    "            print(f\"[UYARI] {test_cell}: SHAP hesaplanamadı. ({type(e_auto).__name__}: {e_auto})\")\n",
    "            shap_arr = None\n",
    "\n",
    "    # SHAP görseller/CSV (başarılıysa)\n",
    "    if shap_arr is not None and shap_arr.ndim == 2 and shap_arr.shape[0] == len(X_test):\n",
    "        # Summary (beeswarm)\n",
    "        try:\n",
    "            plt.figure()\n",
    "            shap.summary_plot(shap_arr, X_test, feature_names=X_test.columns, show=False)\n",
    "            fig_path = os.path.join(OUT_DIR, f\"shap_summary_{test_cell}.png\")\n",
    "            plt.tight_layout(); plt.savefig(fig_path, dpi=200, bbox_inches=\"tight\"); plt.close()\n",
    "        except Exception as e_sum:\n",
    "            print(f\"[UYARI] {test_cell}: SHAP summary çizimi başarısız: {e_sum}\")\n",
    "\n",
    "        # SHAP değerleri CSV\n",
    "        try:\n",
    "            shap_df = pd.DataFrame(shap_arr, columns=X_test.columns)\n",
    "            shap_csv = os.path.join(OUT_DIR, f\"shap_values_{test_cell}.csv\")\n",
    "            shap_df.to_csv(shap_csv, index=False)\n",
    "        except Exception as e_csv:\n",
    "            print(f\"[UYARI] {test_cell}: SHAP CSV yazımı başarısız: {e_csv}\")\n",
    "\n",
    "        # En önemli ilk 3 özellik için bağımlılık grafikleri\n",
    "        try:\n",
    "            mean_abs = np.abs(shap_arr).mean(axis=0)\n",
    "            order = np.argsort(-mean_abs)\n",
    "            top_features = [X_test.columns[i] for i in order[:min(3, X_test.shape[1])]]\n",
    "            for feat in top_features:\n",
    "                plt.figure()\n",
    "                shap.dependence_plot(\n",
    "                    ind=feat, shap_values=shap_arr, features=X_test, feature_names=X_test.columns,\n",
    "                    show=False, interaction_index=None\n",
    "                )\n",
    "                dep_path = os.path.join(OUT_DIR, f\"shap_dependence_{test_cell}_{feat}.png\")\n",
    "                plt.tight_layout(); plt.savefig(dep_path, dpi=200, bbox_inches=\"tight\"); plt.close()\n",
    "        except Exception as e_dep:\n",
    "            print(f\"[UYARI] {test_cell}: SHAP dependence çizimi başarısız: {e_dep}\")\n",
    "    else:\n",
    "        print(f\"[UYARI] {test_cell}: SHAP değerleri üretilemedi, görsel atlandı.\")\n",
    "\n",
    "# Sonuç tablosu\n",
    "res_df = pd.DataFrame(results)\n",
    "res_csv = os.path.join(OUT_DIR, \"flaml_loco_results.csv\")\n",
    "res_df.to_csv(res_csv, index=False)\n",
    "display(res_df)\n",
    "print(f\"[KAYIT] Sonuç tablosu: {res_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "068f59e9-f44e-4945-9ce0-1b6e005e61ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP hazır: flaml_shap_outputs.zip\n"
     ]
    }
   ],
   "source": [
    "zip_path = \"flaml_shap_outputs.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "    for root, _, files in os.walk(OUT_DIR):\n",
    "        for f in files:\n",
    "            full = os.path.join(root, f)\n",
    "            rel  = os.path.relpath(full, \".\")\n",
    "            zf.write(full, rel)\n",
    "print(f\"ZIP hazır: {zip_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4112758-b2c6-4a9b-b0bd-90b27ccaff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EvalML-style SHAP beeswarm (FLAML) ===\n",
    "# Amaç: outputs_flaml_shap/shap_values_<CELL_ID>.csv (yoksa /mnt/data yolunu) okuyup,\n",
    "#       orijinal X (Cycle, Peak, Temperature) ile aynı uzunlukta hizalayarak\n",
    "#       EvalML'e benzer yatay beeswarm grafiği üretmek.\n",
    "import os, re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# ---------------- Parametre ----------------\n",
    "CELL_ID = \"Cell1\"  # ör. \"Cell4\", \"Cell8\" vb.\n",
    "OUT_PNG = f\"shap_importance_{CELL_ID}_flaml.png\"\n",
    "\n",
    "# ---------------- Yardımcılar --------------\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]\", \"\", str(s).strip().lower())\n",
    "\n",
    "def _find_idx(cols, alias_set):\n",
    "    ncols = [_norm(c) for c in cols]\n",
    "    for i,n in enumerate(ncols):\n",
    "        if n in alias_set:\n",
    "            return i\n",
    "    for i,n in enumerate(ncols):\n",
    "        if any(a in n for a in alias_set):\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "# ---------------- SHAP değerlerini yükle ---------------\n",
    "shap_csv_main = f\"./outputs_flaml_shap/shap_values_{CELL_ID}.csv\"\n",
    "shap_csv_alt  = f\"/mnt/data/shap_values_{CELL_ID}.csv\"\n",
    "shap_xls_alt  = f\"/mnt/data/shap_values_{CELL_ID}.xls\"\n",
    "\n",
    "if   os.path.exists(shap_csv_main): shap_df = pd.read_csv(shap_csv_main)\n",
    "elif os.path.exists(shap_csv_alt):  shap_df = pd.read_csv(shap_csv_alt)\n",
    "elif os.path.exists(shap_xls_alt):  shap_df = pd.read_excel(shap_xls_alt)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"SHAP dosyası bulunamadı: {shap_csv_main} / {shap_csv_alt} / {shap_xls_alt}\")\n",
    "\n",
    "# ---------------- Özellik değerlerini (X) yükle --------\n",
    "# Ham dosya adı kalıbı: CellX_Cycle_Peak_meanT_SoH.csv\n",
    "cand = sorted(glob.glob(f\"./{CELL_ID}_Cycle_Peak_meanT_SoH.csv\")) or \\\n",
    "       sorted(glob.glob(f\"/mnt/data/{CELL_ID}_Cycle_Peak_meanT_SoH.csv\"))\n",
    "if not cand:\n",
    "    raise FileNotFoundError(f\"{CELL_ID}_Cycle_Peak_meanT_SoH.csv dosyası bulunamadı (., /mnt/data).\")\n",
    "raw = pd.read_csv(cand[0])\n",
    "\n",
    "cols = list(raw.columns)\n",
    "idx_cycle = _find_idx(cols, {\"cycle\",\"cycles\",\"efc\",\"equivalentfullcycles\",\"cyclecount\"})\n",
    "idx_peak  = _find_idx(cols, {\"peak\",\"pmax\",\"icpeak\",\"normalizedpeak\",\"normalizedpmax\",\"normalizedicpeak\"})\n",
    "idx_temp  = _find_idx(cols, {\"meantemperature\",\"temperature\",\"meantemp\",\"avgtemp\",\"tmean\"})\n",
    "\n",
    "if None in (idx_cycle, idx_peak, idx_temp):\n",
    "    raise ValueError(f\"Zorunlu kolon(lar) yok. Mevcut başlıklar: {cols}\")\n",
    "\n",
    "X = pd.DataFrame({\n",
    "    \"Cycle\":           pd.to_numeric(raw.iloc[:, idx_cycle], errors=\"coerce\"),\n",
    "    \"Normalized_Peak\": pd.to_numeric(raw.iloc[:, idx_peak],  errors=\"coerce\"),\n",
    "    \"Temperature\":     pd.to_numeric(raw.iloc[:, idx_temp],  errors=\"coerce\"),\n",
    "}).dropna()\n",
    "\n",
    "# --- SHAP ve X uzunluklarını hizala (gerekirse kırp) ---\n",
    "min_len = min(len(shap_df), len(X))\n",
    "X = X.iloc[:min_len, :].reset_index(drop=True)\n",
    "# shap_df kolonlarını eşle: cycle/peak/temperature benzeri isimler olabilir\n",
    "sc_map = {\n",
    "    \"Normalized_Peak\": [c for c in shap_df.columns if _norm(c) in {\"peak\",\"pmax\",\"icpeak\",\"normalizedpeak\",\"normalizedpmax\",\"normalizedicpeak\"}],\n",
    "    \"Cycle\":           [c for c in shap_df.columns if _norm(c) == \"cycle\" or \"cycle\" in _norm(c)],\n",
    "    \"Temperature\":     [c for c in shap_df.columns if \"temp\" in _norm(c) or \"temperature\" in _norm(c)],\n",
    "}\n",
    "for k in sc_map:\n",
    "    if not sc_map[k]:\n",
    "        raise ValueError(f\"{k} için SHAP kolonu bulunamadı. SHAP kolonları: {list(shap_df.columns)}\")\n",
    "    sc_map[k] = sc_map[k][0]\n",
    "S = shap_df.loc[:min_len-1, [sc_map[\"Normalized_Peak\"], sc_map[\"Cycle\"], sc_map[\"Temperature\"]]]\n",
    "S.columns = [\"Normalized_Peak\",\"Cycle\",\"Temperature\"]\n",
    "\n",
    "# ---------------- Çizim (EvalML-style) -----------------\n",
    "# Sıra: üstte Normalized_Peak, ortada Cycle, altta Temperature\n",
    "plot_order = [\"Normalized_Peak\",\"Cycle\",\"Temperature\"]\n",
    "ypos = {\"Temperature\":0, \"Cycle\":1, \"Normalized_Peak\":2}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 3.2))\n",
    "cmap = plt.cm.coolwarm\n",
    "\n",
    "for feat in plot_order:\n",
    "    xs = S[feat].values\n",
    "    ys = np.full_like(xs, ypos[feat], dtype=float)\n",
    "    # hafif jitter\n",
    "    jitter = (np.random.rand(len(xs)) - 0.5) * 0.5\n",
    "    # renk: ilgili feature değerleri min-max normalize\n",
    "    vals = X[feat].values\n",
    "    vmin, vmax = np.nanmin(vals), np.nanmax(vals)\n",
    "    colors = cmap((vals - vmin)/(vmax - vmin) if vmax>vmin else np.zeros_like(vals))\n",
    "    ax.scatter(xs, ys + jitter, s=14, alpha=0.9, edgecolors=\"none\", c=colors)\n",
    "\n",
    "# y-tick etiketleri\n",
    "ax.set_yticks([0,1,2])\n",
    "ax.set_yticklabels([\"Temperature\",\"Cycle\",\"Normalized_Peak\"])\n",
    "\n",
    "# dikey 0 çizgisi\n",
    "ax.axvline(0, color=\"gray\", linewidth=1)\n",
    "\n",
    "# x-izgara (hafif noktalı)\n",
    "ax.grid(True, axis=\"x\", linestyle=\":\", linewidth=0.6, alpha=0.6)\n",
    "ax.grid(False, axis=\"y\")\n",
    "\n",
    "# başlık ve eksen\n",
    "ax.set_title(f\"EvalML-style SHAP (Cell: {CELL_ID})\", fontsize=14, pad=8)\n",
    "ax.set_xlabel(\"SHAP value (impact on model output)\")\n",
    "\n",
    "# renk barı (Low→High)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=Normalize(vmin=0, vmax=1))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label(\"Feature value\", rotation=90)\n",
    "cbar.set_ticks([0,1])\n",
    "cbar.set_ticklabels([\"Low\",\"High\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_PNG, dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Kaydedildi: {OUT_PNG}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (flaml-shap)",
   "language": "python",
   "name": "flaml-shap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
