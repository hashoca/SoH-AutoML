{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3fa44c-0fd7-4dcd-939b-b7a4cecfc971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Kurulum & Ayarlar ====\n",
    "import os, re, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import shap  # SHAP grafikleri için\n",
    "\n",
    "# Dosya adı (aynı klasördeyse bu şekilde bırak)\n",
    "DATA_FILE = \"MOHTAT_dataset_4_PeerJ.xlsx\"   # gerekirse tam yolu yaz\n",
    "OUT_DIR   = \"./outputs_flaml_shap\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# FLAML ayarları\n",
    "TIME_BUDGET_SEC = 300   # 300-900 arası önerilir\n",
    "SEED = 42\n",
    "N_JOBS = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81a008ac-c1e4-4404-88f1-ff1e4282ad13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hücreler: ['Cell01', 'Cell03', 'Cell10', 'Cell11', 'Cell12']\n",
      "Özellikler: ['Cycle', 'Normalized_Peak', 'Temperature']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Battery</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>SoH</th>\n",
       "      <th>Normalized_Peak</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cell01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cell01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.996359</td>\n",
       "      <td>1.025722</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cell01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.997099</td>\n",
       "      <td>0.975626</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cell01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.994473</td>\n",
       "      <td>1.012685</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.994391</td>\n",
       "      <td>0.975566</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cell01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.992173</td>\n",
       "      <td>0.987661</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cell01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.975672</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cell01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.990925</td>\n",
       "      <td>0.975637</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Battery  Cycle       SoH  Normalized_Peak  Temperature\n",
       "0  Cell01    1.0  1.000000         1.000000         25.0\n",
       "1  Cell01    2.0  0.996359         1.025722         25.0\n",
       "2  Cell01    3.0  0.997099         0.975626         25.0\n",
       "3  Cell01    4.0  0.994473         1.012685         25.0\n",
       "4  Cell01    5.0  0.994391         0.975566         25.0\n",
       "5  Cell01    6.0  0.992173         0.987661         25.0\n",
       "6  Cell01    7.0  0.991241         0.975672         25.0\n",
       "7  Cell01    8.0  0.990925         0.975637         25.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==== Veri Okuma & Temizleme (tek sayfa, Battery sütunu) ====\n",
    "\n",
    "def to_num(x):\n",
    "    \"\"\"Virgüllü ondalıkları (örn: '0,987') noktaya çevirerek float yap.\"\"\"\n",
    "    if pd.isna(x): return np.nan\n",
    "    if isinstance(x, str):\n",
    "        x = x.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]\", \"\", str(s).strip().lower())\n",
    "\n",
    "def pick_col(cols, candidates):\n",
    "    \"\"\"Kolon adlarını esnek eşle: 'Cycle', 'SoH', 'Normalized_Peak', 'Temperature' için.\"\"\"\n",
    "    ncols = [_norm(c) for c in cols]\n",
    "    candn = {_norm(c) for c in candidates}\n",
    "    # tam eşleşme\n",
    "    for i, n in enumerate(ncols):\n",
    "        if n in candn:\n",
    "            return cols[i]\n",
    "    # kısmi eşleşme\n",
    "    for i, n in enumerate(ncols):\n",
    "        for a in candn:\n",
    "            if a and a in n:\n",
    "                return cols[i]\n",
    "    return None\n",
    "\n",
    "# Dosyayı oku (tek sayfa)\n",
    "raw = pd.read_excel(DATA_FILE, sheet_name=0)\n",
    "\n",
    "# Zorunlu/opsiyonel kolonları bul\n",
    "col_batt = pick_col(raw.columns, {\"battery\",\"cell\",\"cellid\",\"batteryid\"})\n",
    "col_cycle = pick_col(raw.columns, {\"cycle\",\"cycles\",\"efc\",\"equivalentfullcycles\"})\n",
    "col_soh = pick_col(raw.columns, {\"soh\",\"stateofhealth\"})\n",
    "col_peak = pick_col(raw.columns, {\"normalized_peak\",\"normalizedpmax\",\"normalizedicpeak\",\"peak\",\"pmax\",\"icpeak\"})\n",
    "col_temp = pick_col(raw.columns, {\"temperature\",\"meant\",\"mean_temperature\",\"temp\",\"avgtemp\"})\n",
    "\n",
    "missing = [name for name, col in {\n",
    "    \"Battery\": col_batt, \"Cycle\": col_cycle, \"SoH\": col_soh, \"Normalized_Peak\": col_peak\n",
    "}.items() if col is None]\n",
    "if missing:\n",
    "    raise ValueError(f\"Zorunlu kolon(lar) eksik: {missing}\\nMevcut kolonlar: {list(raw.columns)}\")\n",
    "\n",
    "# Standart tablo\n",
    "data = pd.DataFrame({\n",
    "    \"Battery\": raw[col_batt].astype(str),\n",
    "    \"Cycle\": raw[col_cycle].map(to_num),\n",
    "    \"SoH\": raw[col_soh].map(to_num),\n",
    "    \"Normalized_Peak\": raw[col_peak].map(to_num),\n",
    "})\n",
    "if col_temp is not None:\n",
    "    data[\"Temperature\"] = raw[col_temp].map(to_num)\n",
    "\n",
    "# Temizle\n",
    "data = data.dropna(subset=[\"Cycle\",\"SoH\",\"Normalized_Peak\"]).copy()\n",
    "\n",
    "# Özellik listesi (Temperature opsiyonel)\n",
    "feature_cols = [\"Cycle\",\"Normalized_Peak\"]\n",
    "if \"Temperature\" in data.columns and data[\"Temperature\"].notna().any():\n",
    "    feature_cols.append(\"Temperature\")\n",
    "\n",
    "# Hücre listesi (Battery = Cell01/Cell02…)\n",
    "def _cell_key(x):\n",
    "    m = re.search(r\"\\d+\", x)\n",
    "    return int(m.group(0)) if m else 999\n",
    "cells = sorted(data[\"Battery\"].unique(), key=_cell_key)\n",
    "\n",
    "print(\"Hücreler:\", cells)\n",
    "print(\"Özellikler:\", feature_cols)\n",
    "display(data.head(8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3100d825-1b7e-4c42-9da4-d148cbee0421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Cell</th>\n",
       "      <th>Best_Estimator</th>\n",
       "      <th>Best_Config</th>\n",
       "      <th>Best_Iteration</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cell01</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>{'n_estimators': 225, 'max_leaves': 83, 'min_c...</td>\n",
       "      <td>411</td>\n",
       "      <td>0.029635</td>\n",
       "      <td>0.027489</td>\n",
       "      <td>0.862294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cell03</td>\n",
       "      <td>rf</td>\n",
       "      <td>{'n_estimators': 86, 'max_features': 1.0, 'max...</td>\n",
       "      <td>451</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.865423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cell10</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>{'n_estimators': 211, 'max_leaves': 99, 'min_c...</td>\n",
       "      <td>598</td>\n",
       "      <td>0.036275</td>\n",
       "      <td>0.034007</td>\n",
       "      <td>0.723274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cell11</td>\n",
       "      <td>extra_tree</td>\n",
       "      <td>{'n_estimators': 189, 'max_features': 1.0, 'ma...</td>\n",
       "      <td>408</td>\n",
       "      <td>0.023208</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>0.914586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell12</td>\n",
       "      <td>extra_tree</td>\n",
       "      <td>{'n_estimators': 36, 'max_features': 1.0, 'max...</td>\n",
       "      <td>199</td>\n",
       "      <td>0.032205</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0.857266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test_Cell Best_Estimator                                        Best_Config  \\\n",
       "0    Cell01        xgboost  {'n_estimators': 225, 'max_leaves': 83, 'min_c...   \n",
       "1    Cell03             rf  {'n_estimators': 86, 'max_features': 1.0, 'max...   \n",
       "2    Cell10        xgboost  {'n_estimators': 211, 'max_leaves': 99, 'min_c...   \n",
       "3    Cell11     extra_tree  {'n_estimators': 189, 'max_features': 1.0, 'ma...   \n",
       "4    Cell12     extra_tree  {'n_estimators': 36, 'max_features': 1.0, 'max...   \n",
       "\n",
       "   Best_Iteration      RMSE       MAE        R2  \n",
       "0             411  0.029635  0.027489  0.862294  \n",
       "1             451  0.016789  0.014492  0.865423  \n",
       "2             598  0.036275  0.034007  0.723274  \n",
       "3             408  0.023208  0.016510  0.914586  \n",
       "4             199  0.032205  0.022821  0.857266  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KAYIT] Sonuç tablosu: ./outputs_flaml_shap\\flaml_loco_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ==== LOCO + FLAML + SHAP (temiz, hatasız) ====\n",
    "\n",
    "def to_numeric_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Virgüllü ondalıkları noktaya çevirip sayıya dönüştürür (tüm DataFrame).\"\"\"\n",
    "    return (df.astype(str)\n",
    "              .apply(lambda s: s.str.replace(\",\", \".\", regex=False))\n",
    "              .apply(pd.to_numeric, errors=\"coerce\"))\n",
    "\n",
    "def to_numeric_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Virgüllü ondalıkları noktaya çevirip sayıya dönüştürür (Series).\"\"\"\n",
    "    return pd.to_numeric(s.astype(str).str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for test_cell in cells:\n",
    "    # LOCO: bir hücre test, diğerleri train\n",
    "    train_df = data[data[\"Battery\"] != test_cell].copy()\n",
    "    test_df  = data[data[\"Battery\"] == test_cell].copy()\n",
    "\n",
    "    if len(train_df) == 0 or len(test_df) == 0:\n",
    "        print(f\"[UYARI] {test_cell}: boş fold, atlandı.\")\n",
    "        continue\n",
    "\n",
    "    # Özellik ve hedefi ayır\n",
    "    X_train_raw, y_train_raw = train_df[feature_cols], train_df[\"SoH\"]\n",
    "    X_test_raw,  y_test_raw  = test_df[feature_cols],  test_df[\"SoH\"]\n",
    "\n",
    "    # --- Güvenli numeric dönüşüm (vektörize) ---\n",
    "    X_train = to_numeric_df(X_train_raw).replace([np.inf, -np.inf], np.nan)\n",
    "    y_train = to_numeric_series(y_train_raw).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    X_test  = to_numeric_df(X_test_raw).replace([np.inf, -np.inf], np.nan)\n",
    "    y_test  = to_numeric_series(y_test_raw).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # --- NaN hizalama ve atma ---\n",
    "    # Train\n",
    "    train_mask = X_train.notna().all(axis=1) & y_train.notna()\n",
    "    X_train, y_train = X_train.loc[train_mask], y_train.loc[train_mask]\n",
    "\n",
    "    # Test\n",
    "    test_mask = X_test.notna().all(axis=1) & y_test.notna()\n",
    "    X_test, y_test = X_test.loc[test_mask], y_test.loc[test_mask]\n",
    "\n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        print(f\"[UYARI] {test_cell}: NaN/inf temizliği sonrası boş, atlandı.\")\n",
    "        continue\n",
    "\n",
    "    # ---- FLAML ----\n",
    "    automl = AutoML()\n",
    "    automl.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        task=\"regression\",\n",
    "        time_budget=TIME_BUDGET_SEC,\n",
    "        metric=\"rmse\",\n",
    "        estimator_list=[\"lgbm\", \"xgboost\", \"rf\", \"extra_tree\"],  # ağaç tabanlı, SHAP uyumlu\n",
    "        n_jobs=N_JOBS, seed=SEED, verbose=0\n",
    "    )\n",
    "\n",
    "    # Metrikler\n",
    "    y_pred = automl.predict(X_test)\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Test_Cell\": test_cell,\n",
    "        \"Best_Estimator\": automl.best_estimator,\n",
    "        \"Best_Config\": automl.best_config,\n",
    "        \"Best_Iteration\": automl.best_iteration,\n",
    "        \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2\n",
    "    })\n",
    "\n",
    "    # ---- SHAP ----\n",
    "    base_model = getattr(automl.model, \"model\", automl.model)\n",
    "    shap_vals = None\n",
    "    try:\n",
    "        # Hızlı yol: TreeExplainer\n",
    "        explainer = shap.TreeExplainer(base_model)\n",
    "        shap_vals = explainer.shap_values(X_test)\n",
    "        if isinstance(shap_vals, list):\n",
    "            shap_vals = shap_vals[0]\n",
    "        shap_vals = np.asarray(shap_vals)\n",
    "    except Exception:\n",
    "        # Genel Explainer (fallback)\n",
    "        try:\n",
    "            bg = X_train.sample(min(1000, len(X_train)), random_state=SEED)\n",
    "            masker = shap.maskers.Independent(bg, max_samples=1000)\n",
    "            explainer = shap.Explainer(base_model, masker)\n",
    "            sv = explainer(X_test, check_additivity=False)\n",
    "            shap_vals = np.asarray(sv.values)\n",
    "        except Exception as e:\n",
    "            print(f\"[UYARI] {test_cell}: SHAP hesaplanamadı: {type(e).__name__}: {e}\")\n",
    "            shap_vals = None\n",
    "\n",
    "    if shap_vals is not None and shap_vals.ndim == 2 and shap_vals.shape[0] == len(X_test):\n",
    "        # SHAP summary (beeswarm)\n",
    "        try:\n",
    "            plt.figure()\n",
    "            shap.summary_plot(shap_vals, X_test, feature_names=X_test.columns, show=False)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(OUT_DIR, f\"shap_summary_{test_cell}.png\"),\n",
    "                        dpi=200, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"[UYARI] {test_cell}: SHAP summary çizimi hata: {e}\")\n",
    "\n",
    "        # SHAP CSV\n",
    "        try:\n",
    "            pd.DataFrame(shap_vals, columns=X_test.columns).to_csv(\n",
    "                os.path.join(OUT_DIR, f\"shap_values_{test_cell}.csv\"), index=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[UYARI] {test_cell}: SHAP CSV yazımı hata: {e}\")\n",
    "\n",
    "        # En önemli 3 özellik için dependence plot\n",
    "        try:\n",
    "            mean_abs = np.abs(shap_vals).mean(axis=0)\n",
    "            order = np.argsort(-mean_abs)\n",
    "            top_feats = [X_test.columns[i] for i in order[:min(3, X_test.shape[1])]]\n",
    "            for f in top_feats:\n",
    "                plt.figure()\n",
    "                shap.dependence_plot(\n",
    "                    ind=f, shap_values=shap_vals, features=X_test,\n",
    "                    feature_names=X_test.columns, interaction_index=None, show=False\n",
    "                )\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(OUT_DIR, f\"shap_dependence_{test_cell}_{f}.png\"),\n",
    "                            dpi=200, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"[UYARI] {test_cell}: dependence çizimi hata: {e}\")\n",
    "    else:\n",
    "        print(f\"[UYARI] {test_cell}: SHAP üretilemedi, görseller atlandı.\")\n",
    "\n",
    "# Sonuç tablosu\n",
    "res_df = pd.DataFrame(results)\n",
    "res_path = os.path.join(OUT_DIR, \"flaml_loco_results.csv\")\n",
    "res_df.to_csv(res_path, index=False)\n",
    "display(res_df)\n",
    "print(\"[KAYIT] Sonuç tablosu:\", res_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "871fe3dd-ec5d-4922-b19b-cf8fdfaabbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ZIP hazır: flaml_shap_outputs_mohtat.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "ZIP_PATH = \"flaml_shap_outputs_mohtat.zip\"   # istersen adını değiştir\n",
    "\n",
    "with zipfile.ZipFile(ZIP_PATH, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "    for root, _, files in os.walk(OUT_DIR):\n",
    "        for f in files:\n",
    "            full_path = os.path.join(root, f)\n",
    "            rel_path  = os.path.relpath(full_path, \".\")\n",
    "            zf.write(full_path, rel_path)\n",
    "\n",
    "print(f\"✅ ZIP hazır: {ZIP_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c256ce-a076-4169-bfd1-88d844249464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== LOCO + FLAML + SHAP + MODEL KAYDETME ====\n",
    "\n",
    "from joblib import dump\n",
    "import json\n",
    "\n",
    "def to_numeric_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (df.astype(str)\n",
    "              .apply(lambda s: s.str.replace(\",\", \".\", regex=False))\n",
    "              .apply(pd.to_numeric, errors=\"coerce\"))\n",
    "\n",
    "def to_numeric_series(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(s.astype(str).str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "\n",
    "results = []\n",
    "MODEL_DIR = os.path.join(OUT_DIR, \"models\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Tüm deneyde kullanılan özellik setini da kaydedelim\n",
    "with open(os.path.join(MODEL_DIR, \"feature_cols.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(feature_cols, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "for test_cell in cells:\n",
    "    # LOCO: bir hücre test, diğerleri train\n",
    "    train_df = data[data[\"Battery\"] != test_cell].copy()\n",
    "    test_df  = data[data[\"Battery\"] == test_cell].copy()\n",
    "\n",
    "    if len(train_df) == 0 or len(test_df) == 0:\n",
    "        print(f\"[UYARI] {test_cell}: boş fold, atlandı.\")\n",
    "        continue\n",
    "\n",
    "    # Özellik ve hedefi ayır\n",
    "    X_train_raw, y_train_raw = train_df[feature_cols], train_df[\"SoH\"]\n",
    "    X_test_raw,  y_test_raw  = test_df[feature_cols],  test_df[\"SoH\"]\n",
    "\n",
    "    # --- Güvenli numeric dönüşüm (vektörize) ---\n",
    "    X_train = to_numeric_df(X_train_raw).replace([np.inf, -np.inf], np.nan)\n",
    "    y_train = to_numeric_series(y_train_raw).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    X_test  = to_numeric_df(X_test_raw).replace([np.inf, -np.inf], np.nan)\n",
    "    y_test  = to_numeric_series(y_test_raw).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # --- NaN hizalama ve atma ---\n",
    "    train_mask = X_train.notna().all(axis=1) & y_train.notna()\n",
    "    X_train, y_train = X_train.loc[train_mask], y_train.loc[train_mask]\n",
    "\n",
    "    test_mask = X_test.notna().all(axis=1) & y_test.notna()\n",
    "    X_test, y_test = X_test.loc[test_mask], y_test.loc[test_mask]\n",
    "\n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        print(f\"[UYARI] {test_cell}: NaN/inf temizliği sonrası boş, atlandı.\")\n",
    "        continue\n",
    "\n",
    "    # ---- FLAML ----\n",
    "    automl = AutoML()\n",
    "    automl.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        task=\"regression\",\n",
    "        time_budget=TIME_BUDGET_SEC,\n",
    "        metric=\"rmse\",\n",
    "        estimator_list=[\"lgbm\", \"xgboost\", \"rf\", \"extra_tree\"],  # ağaç tabanlı, SHAP uyumlu\n",
    "        n_jobs=N_JOBS, seed=SEED, verbose=0\n",
    "    )\n",
    "\n",
    "    # Metrikler\n",
    "    y_pred = automl.predict(X_test)\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    mae  = mean_absolute_error(y_test, y_pred)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Test_Cell\": test_cell,\n",
    "        \"Best_Estimator\": automl.best_estimator,\n",
    "        \"Best_Config\": automl.best_config,\n",
    "        \"Best_Iteration\": automl.best_iteration,\n",
    "        \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2\n",
    "    })\n",
    "\n",
    "    # === Model & verileri kaydet ===\n",
    "    # 1) Tüm AutoML nesnesi (tüm bilgilerle)\n",
    "    dump(automl, os.path.join(MODEL_DIR, f\"automl_{test_cell}.joblib\"))\n",
    "    # 2) En iyi model (sadece tahminci)\n",
    "    dump(automl.model, os.path.join(MODEL_DIR, f\"bestmodel_{test_cell}.joblib\"))\n",
    "    # 3) Test verisi ve etiket\n",
    "    X_test.to_csv(os.path.join(MODEL_DIR, f\"X_test_{test_cell}.csv\"), index=True)\n",
    "    y_test.to_csv(os.path.join(MODEL_DIR, f\"y_test_{test_cell}.csv\"), index=True)\n",
    "    # 4) SHAP masker için arka plan (eğer tekrar üretmek istersek)\n",
    "    bg = X_train.sample(min(1000, len(X_train)), random_state=SEED)\n",
    "    bg.to_csv(os.path.join(MODEL_DIR, f\"bg_{test_cell}.csv\"), index=True)\n",
    "\n",
    "    # ---- SHAP ----\n",
    "    base_model = getattr(automl.model, \"model\", automl.model)\n",
    "    shap_vals = None\n",
    "    try:\n",
    "        # Hızlı yol: TreeExplainer\n",
    "        explainer = shap.TreeExplainer(base_model)\n",
    "        shap_vals = explainer.shap_values(X_test)\n",
    "        if isinstance(shap_vals, list):\n",
    "            shap_vals = shap_vals[0]\n",
    "        shap_vals = np.asarray(shap_vals)\n",
    "    except Exception:\n",
    "        # Genel Explainer (fallback)\n",
    "        try:\n",
    "            masker = shap.maskers.Independent(bg, max_samples=1000)\n",
    "            explainer = shap.Explainer(base_model, masker)\n",
    "            sv = explainer(X_test, check_additivity=False)\n",
    "            shap_vals = np.asarray(sv.values)\n",
    "        except Exception as e:\n",
    "            print(f\"[UYARI] {test_cell}: SHAP hesaplanamadı: {type(e).__name__}: {e}\")\n",
    "            shap_vals = None\n",
    "\n",
    "    if shap_vals is not None and shap_vals.ndim == 2 and shap_vals.shape[0] == len(X_test):\n",
    "        # SHAP summary (beeswarm)\n",
    "        try:\n",
    "            plt.figure()\n",
    "            shap.summary_plot(shap_vals, X_test, feature_names=X_test.columns, show=False)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(OUT_DIR, f\"shap_summary_{test_cell}.png\"),\n",
    "                        dpi=200, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"[UYARI] {test_cell}: SHAP summary çizimi hata: {e}\")\n",
    "\n",
    "        # SHAP CSV\n",
    "        try:\n",
    "            pd.DataFrame(shap_vals, columns=X_test.columns).to_csv(\n",
    "                os.path.join(OUT_DIR, f\"shap_values_{test_cell}.csv\"), index=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[UYARI] {test_cell}: SHAP CSV yazımı hata: {e}\")\n",
    "\n",
    "        # En önemli 3 özellik için dependence plot\n",
    "        try:\n",
    "            mean_abs = np.abs(shap_vals).mean(axis=0)\n",
    "            order = np.argsort(-mean_abs)\n",
    "            top_feats = [X_test.columns[i] for i in order[:min(3, X_test.shape[1])]]\n",
    "            for f in top_feats:\n",
    "                plt.figure()\n",
    "                shap.dependence_plot(\n",
    "                    ind=f, shap_values=shap_vals, features=X_test,\n",
    "                    feature_names=X_test.columns, interaction_index=None, show=False\n",
    "                )\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(OUT_DIR, f\"shap_dependence_{test_cell}_{f}.png\"),\n",
    "                            dpi=200, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"[UYARI] {test_cell}: dependence çizimi hata: {e}\")\n",
    "    else:\n",
    "        print(f\"[UYARI] {test_cell}: SHAP üretilemedi, görseller atlandı.\")\n",
    "\n",
    "# Sonuç tablosu\n",
    "res_df = pd.DataFrame(results)\n",
    "res_path = os.path.join(OUT_DIR, \"flaml_loco_results.csv\")\n",
    "res_df.to_csv(res_path, index=False)\n",
    "display(res_df)\n",
    "print(\"[KAYIT] Sonuç tablosu:\", res_path)\n",
    "print(\"[KAYIT] Modeller ve veri parçaları:\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c9757-4504-4a68-ae6a-3d5807461a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== MODELİ YÜKLE, AYNI BATTERY İÇİN GRAFİKLERİ TEKRAR ÜRET ====\n",
    "\n",
    "from joblib import load\n",
    "import json\n",
    "\n",
    "SELECT_BATTERY = \"Cell01\"   # örn: \"Cell02\", \"Cell07\" ...\n",
    "\n",
    "# 1) Özellik listesini ve modeli yükle\n",
    "with open(os.path.join(MODEL_DIR, \"feature_cols.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    feature_cols_saved = json.load(f)\n",
    "\n",
    "automl = load(os.path.join(MODEL_DIR, f\"automl_{SELECT_BATTERY}.joblib\"))\n",
    "best_model = load(os.path.join(MODEL_DIR, f\"bestmodel_{SELECT_BATTERY}.joblib\"))\n",
    "\n",
    "# 2) Veri ve arka plan örneklemini yükle\n",
    "raw = pd.read_excel(DATA_FILE, sheet_name=0)\n",
    "# önceki yardımcıları kullanarak kolonları bulalım (Hücre 2’de tanımladık: pick_col)\n",
    "col_batt = pick_col(raw.columns, {\"battery\",\"cell\",\"cellid\",\"batteryid\"})\n",
    "# Excel’den bu Battery’ye ait satırları al\n",
    "mask = raw[col_batt].astype(str) == SELECT_BATTERY\n",
    "subset = raw.loc[mask, :]\n",
    "\n",
    "# Feature kolonlarını (saved order) vektörize numeric’e çevir\n",
    "def to_numeric_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (df.astype(str)\n",
    "              .apply(lambda s: s.str.replace(\",\", \".\", regex=False))\n",
    "              .apply(pd.to_numeric, errors=\"coerce\"))\n",
    "\n",
    "X = to_numeric_df(subset[feature_cols_saved]).replace([np.inf,-np.inf], np.nan).dropna()\n",
    "\n",
    "# 3) SHAP hesapla (TreeExplainer dene; olmazsa masker kullan)\n",
    "base_model = getattr(best_model, \"model\", best_model)\n",
    "try:\n",
    "    explainer = shap.TreeExplainer(base_model)\n",
    "    shap_vals = explainer.shap_values(X)\n",
    "    if isinstance(shap_vals, list):\n",
    "        shap_vals = shap_vals[0]\n",
    "    shap_vals = np.asarray(shap_vals)\n",
    "except Exception:\n",
    "    # Kaydedilmiş bg varsa onu kullan\n",
    "    bg_path = os.path.join(MODEL_DIR, f\"bg_{SELECT_BATTERY}.csv\")\n",
    "    if not os.path.exists(bg_path):\n",
    "        # başka bir bg dosyası da seçebilirsin; yoksa training’siz genel masker kullan\n",
    "        bg_df = X.sample(min(100, len(X)), random_state=SEED)\n",
    "    else:\n",
    "        bg_df = pd.read_csv(bg_path, index_col=0)\n",
    "    masker = shap.maskers.Independent(bg_df, max_samples=1000)\n",
    "    explainer = shap.Explainer(base_model, masker)\n",
    "    sv = explainer(X, check_additivity=False)\n",
    "    shap_vals = np.asarray(sv.values)\n",
    "\n",
    "# 4) Grafikleri üret ve kaydet\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_vals, X, feature_names=X.columns, show=False)\n",
    "plt.tight_layout()\n",
    "out_png = os.path.join(OUT_DIR, f\"reshap_summary_{SELECT_BATTERY}.png\")\n",
    "plt.savefig(out_png, dpi=200, bbox_inches=\"tight\"); plt.close()\n",
    "print(\"Kaydedildi:\", out_png)\n",
    "\n",
    "# ilk 3 özellik için dependence\n",
    "mean_abs = np.abs(shap_vals).mean(axis=0)\n",
    "order = np.argsort(-mean_abs)\n",
    "top_feats = [X.columns[i] for i in order[:min(3, X.shape[1])]]\n",
    "for f in top_feats:\n",
    "    plt.figure()\n",
    "    shap.dependence_plot(f, shap_vals, X, feature_names=X.columns, interaction_index=None, show=False)\n",
    "    dep_png = os.path.join(OUT_DIR, f\"reshap_dependence_{SELECT_BATTERY}_{f}.png\")\n",
    "    plt.tight_layout(); plt.savefig(dep_png, dpi=200, bbox_inches=\"tight\"); plt.close()\n",
    "    print(\"Kaydedildi:\", dep_png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (flaml-shap)",
   "language": "python",
   "name": "flaml-shap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
